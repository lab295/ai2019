def bfs(graph, start):
    visited, queue = set(), [start]
    while queue:
        vertex = queue.pop(0)
        if vertex not in visited:
            visited.add(vertex)
            queue.extend(graph[vertex]-visited)
    return visited

# sample graph represented as an adjacency list
graph = {
 'A': set(['B', 'C']),
 'B': set(['A', 'D', 'E']),
 'C': set(['A', 'F','G']),
 'D': set(['B']),
 'E': set(['B']),
 'F': set(['C']),
 'G': set(['C'])
}
bfs(graph, 'A')

data = pd.read_csv("Hr.csv")
data.head(5)

data.shape

data.columns

data.info()

dept = data.iloc[:, [5,27]].copy()
dept_per = dept
dept_per.groupby(by='EmpDepartment')['PerformanceRating'].mean()

plt.figure(figsize=(10,4.5))
sns.barplot(x = dept_per['EmpDepartment'],y = dept_per['PerformanceRating'])

dept_per.groupby(by='EmpDepartment')['PerformanceRating'].value_counts()

department = pd.get_dummies(dept_per['EmpDepartment'])
performance = pd.DataFrame(dept_per['PerformanceRating'])
dept_rating = pd.concat([department, performance], axis = 1)

plt.figure(figsize=(15,10))
plt.subplot(2,3,1)
sns.barplot(x= dept_rating['PerformanceRating'],y =dept_rating['Sales'])
plt.subplot(2,3,2)
sns.barplot(x= dept_rating['PerformanceRating'],y=dept_rating['Development'])
plt.subplot(2,3,3)
sns.barplot(x = dept_rating['PerformanceRating'],y=dept_rating['Research & Development'])
plt.subplot(2,3,4)
sns.barplot(x= dept_rating['PerformanceRating'],y=dept_rating['Human Resources'])
plt.subplot(2,3,5)
sns.barplot(x=dept_rating['PerformanceRating'],y=dept_rating['Finance'])
plt.subplot(2,3,6)
sns.barplot(x=dept_rating['PerformanceRating'],y=dept_rating['Data Science'])
plt.show()

enc = LabelEncoder()
for i in (2,3,4,5,6,7,16,26):
 data.iloc[:,i] = enc.fit_transform(data.iloc[:,i])
data.head()

data.corr()

data.drop(['EmpNumber'],inplace=True,axis=1)
data.head(5)

y = data.PerformanceRating
#X = data.iloc[:,0:-1] All predictors were selected it resulted in dropping of accuracy
X = data.iloc[:,[4,5,9,16,20,21,22,23,24]] # Taking only variables with correlation coef
X.head()

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=10)
# Standardization technique is used
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

X_train.shape

X_test.shape

from sklearn.ensemble import RandomForestClassifier
classifier_rfg=RandomForestClassifier(random_state=33,n_estimators=23)
parameters=[{'min_samples_split':[2,3,4,5],'criterion':['gini','entropy'],'min_samples_leaf': [1, 2, 3],'min_samples_split': [2, 3, 4, 5]}]
model_gridrf=GridSearchCV(estimator=classifier_rfg, param_grid=parameters, scoring='accuracy')
model_gridrf.fit(X_train,y_train)

model_gridrf.best_params_

# Predicting the model
y_predict_rf = model_gridrf.predict(X_test)

# Finding accuracy, precision, recall and confusion matrix
print(accuracy_score(y_test,y_predict_rf))
print(classification_report(y_test,y_predict_rf))

confusion_matrix(y_test,y_predict_rf)

You can see the model has 93.05% Accuracy.
The features that are positively correlated are:

Environment Satisfaction

Last Salary Hike Percent

Worklife Balance. (This means that if these factors increases, Performance Rating will increase.)

On the other hand, the features that are negatively correlated are:

Years Since Last Promotion

Experience Years at this Company

Experience years in Current Role

Years with Current Manager. (This means that if these factors increases, Performance Rating will go down.)

Conclusion: The company should provide a better environment as it increases the performance drastically.The company should increase the salary of the employee from time to time and help them maintain a worklife balance, shuffling the manager from time to time will also affect performanceÂ¶